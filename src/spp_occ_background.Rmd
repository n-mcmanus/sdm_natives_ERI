---
title: "Species occurrence data and background points"
author: "Nick McManus"
date: "2023-07-07"
output: html_document
---

```{r setup, include=FALSE, message = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
library(tidyverse)            ## always
library(here)                 ## reading/writing data
library(rgbif)                ## download GBIF data
library(CoordinateCleaner)    ## filter/clean GBIF data
library(terra)                ## rast pkg for quicker reprojecting
library(raster)               ## rast format that plays w/dismo
library(enmSdmX)              ## spatially thinning data
library(dismo)                ## generating background points
library(lfstat)               ## water year fxn
```

This script filters and creates both the species occurrence and background point data files used for the species distribution model in the `kern_sdm` markdown.


# Occurrence Data

## Download/import
This first section will read in, filter, and export species occurrence data from three different sources: GBIF, VegBank, and CalFlora. Both VegBank and CalFlora data are downloaded directly from their websites. GBIF data is imported and filtered using the `rgbif` and `CoordinateCleaner` packages, respectively. 


### CalFlora
This data was directly downloaded from the CalFlora website, found here:
https://www.calflora.org/entry/observ.html

A single CSV was downloaded for each species. We'll read them all in as one dataframe to more easily filter the data. 

*NOTE:* Creating a "low" and "high" filtered version of the data to see how much of a difference strictness over data sources plays. 
```{r}
path = here("data/occ/calflora//")

names <- c(
  "a_polycarpa",
  "p_arborea",
  "c_pungens",
  "l_pentachaeta",
  "p_ciliata",
  "a_menziesii",
  "c_lasiophyllus"
)

# ## List of accepted sources
# sources <- paste(c("BLM",
#                    "Bureau",
#                    "USDA",
#                    "DFW",
#                    "USGS",
#                    "Nature Conservancy",
#                    "TNC",
#                    "CNPS",
#                    "Taylor",
#                    "Hrusa"), collapse = "|")

## Loop through each spp to read in, filter, and export
for (i in 1:length(names)) {
  ## Read in data
  df <- read_csv(paste0(path, "download/", names[i], "_calflora.csv"))
  
  ## filter and keep coords
  df_filter <- df %>% 
    ## "LOW" filter criteria
    filter(`Location Quality` %in% c("high", "medium"),
           `Accuracy: Square Meters` <= 72900,
           Date >= "1999-10-01") 
    ## "HIGH" filter criteria
    # filter(str_detect(.$Source, sources))
    
  ## export
  write_csv(df_filter, paste0(path, names[i], "_calflora_lowFilter.csv"))
}

```



### VegBank
This data was downloaded directly from the VegBank website, found here: http://vegbank.org/vegbank/forms/plot-query.jsp. 

Data for all plots of one spp were downloaded and zipped as a "batch". Information about the plots, contributors, and all the spp and % cover are written as different CSV files. 
Spatial information on the plots is limited; only one coordinate (assuming the center) is given for each plot. Sometimes the size of the plot is provided in m^2, sometimes it's reported qualitatively (e.g. "small" or "large"), and sometimes there is no information. Because presence data will be thinned in the next step, we'll assign one observation point for a plot under 270m^2 in size, regardless of % coverage. For plots where area is not reported, we'll err on the side of caution and only include one point as well. For plots over 270m^2..... TBD. The observation coordinate assigned will be the one reported for the plot in the VegBank database.

*NOTE:* we'll decide if this methodology should be changed later. 
```{r}
path = here("data/occ/vegbank//")

names <- c(
  "a_polycarpa",
  "p_arborea",
  "c_pungens",
  "l_pentachaeta",
  "p_ciliata",
  "a_menziesii"
  ## Not in vegbank
  # "c_lasiophyllus"
)

## Loop to read in, filter, and export for each spp
for (i in 1:length(names)) {
  
  ## Read in data
  plotData <- read_csv(paste0(path, names[i], "_noFilter/plot_env.csv"))
  
  ## filter and keep coords
  plotData_obs <- plotData %>% 
    mutate(date = lubridate::ymd(obsstartdate_vb)) %>% 
    filter(date >= "1999-10-01") %>% 
    ## Filter for under 270. Won't do for now
    # filter(area <= 270 | area == "null") %>% 
    dplyr::select(observation_id, authorplotcode_vb, 
                  project_id_name, date, latitude, longitude) %>% 
    mutate(spp = names[i])
  
  ## export
  write_csv(plotData_obs, paste0(path, names[i], "_vegbank.csv"))
}


```


### GBIF
This script uses the `rgbif` package to directly download species occurrence data from GBIF. To use the `occ_download()` function, this requires setting your GBIF login details. Details on how to set this can be found at: 
https://docs.ropensci.org/rgbif/articles/gbif_credentials.html

```{r}
## Pull taxon keys from list of spp
taxon_keys <- name_backbone_checklist(c(
  ## shrubs
  "Atriplex polycarpa",
  "Peritoma arborea",
  ## forbs
  "Centromadia pungens",
  "Layia pentachaeta subsp. albida D.D.Keck", 
  "Phacelia ciliata Benth.",
  ## spp that naturally colonized
  "Amsinckia menziesii (Lehm.) A.Nelson & J.F.Macbr.",
  "Caulanthus lasiophyllus (Hook. & Arn.) Payson"
)) %>% 
  pull(usageKey)


names <- c(
  "a_polycarpa",
  "p_arborea",
  "c_pungens",
  "l_pentachaeta",
  "p_ciliata",
  "a_menziesii",
  "c_lasiophyllus"
)


## Loop through spp list and save each
for (i in 1:length(taxon_keys)) {
  ### download filtered data for A. polycarpa
  gbif_download <- occ_download(pred_in("taxonKey", taxon_keys[i]),
                         ## remove geospatial issues
                         pred("hasGeospatialIssue", FALSE),
                         ## ensure coords
                         pred("hasCoordinate", TRUE),
                         ## remove "absent" occurences
                         pred("occurrenceStatus", "PRESENT"),
                         ## within US
                         pred("country", "US"),
                         ## within CA
                         pred("stateProvince", "California"),
                         ## uncertainty less than 5000m
                         #pred_lt("coordinateUncertaintyInMeters",5000),
                         ## output as CSV
                         format = "SIMPLE_CSV")
  
  ### check on download status
  occ_download_wait(gbif_download)
  
  ### import GBIF data into env and filter using CoordinateCleaner pkg
   species <- occ_download_get(gbif_download, 
                               path = here("data/occ/gbif/zips/"),
                               overwrite = TRUE) %>%
     occ_download_import() %>% 
     ## set lowercase column names to work with CC
     setNames(tolower(names(.))) %>% 
     ## filter out duplicate points
     distinct(decimallongitude, decimallatitude, 
              specieskey, datasetkey, .keep_all = TRUE) %>% 
     ## filter known uncertainty below 270 and keep NAs
     filter(coordinateuncertaintyinmeters < 270 | 
              is.na(coordinateuncertaintyinmeters)) %>% 
     ## known inaccurate default values
     filter(!coordinateuncertaintyinmeters %in% c(301,3036,999,9999)) %>% 
     ## remove herbaria/zoo locations
     cc_inst(lon = "decimallongitude", lat = "decimallatitude",
             buffer = 270, value = "clean", verbose = TRUE) %>% 
     ## remove ocean values
     cc_sea(lon = "decimallongitude", lat = "decimallatitude") %>% 
     ## remove points before 2000 wy
     filter(eventdate >= "1999-10-01")
   
   ## export file
   write_csv(species, paste0(here("data/occ/gbif//"),names[i],"_gbif.csv"))
   
} ## END LOOP
```

**NOTE:** For *L. pentachaeta*, occurrence ID 2421771841 was manually removed due to likely incorrect coordinates from the institution



## Merge and Spatially Thin

BCMv8 data are available at 270m resolution. To avoid biasing the model to oversampled regions, only one occurrence per 270m pixel will be used for extraction. We'll first combine occurrence data by species across all data sources, then thin and filter the data to be used in the SDM model. 
```{r}
## file paths 
path_gbif <- here("data/occ/gbif//")
path_calflora <- here("data/occ/calflora//")
path_vegbank <- here("data/occ/vegbank//")

## reference raster for thinning
rast <- rast(here('data/bcmv8/2000_2022/aet2020dec.tif')) %>% 
  ## match crs to spp occ data
  project(y = "WGS84")

## spp names
names <- c(
  "a_polycarpa",
  "p_arborea",
  "c_pungens",
  "l_pentachaeta",
  "p_ciliata",
  "a_menziesii",
  "c_lasiophyllus"
)


## Read in, merge, thin, and export for each spp on list
for (i in 1:length(names)) {
  ## GBIF ---------------------
  ### If no data for that species, doesn't contribute to merged file
  if (length(list.files(path_gbif, pattern = names[i])) == 0) {
    gbif = NULL
  } else {
    gbif <- read_csv(paste0(path_gbif, names[i], "_gbif.csv")) %>% 
      ## only select vars of interest
      dplyr::select(c(gbifid, decimallatitude, decimallongitude, eventdate)) %>% 
      ## consistent var names
      rename(id = gbifid,
             lat = decimallatitude,
             lon = decimallongitude,
             date = eventdate) %>%
             ## add source
      mutate(source = "gbif",
             ## remove time from date
             date = as.Date(date))
  }
  
  ## CalFlora -----------------
  if (length(list.files(path_calflora, pattern = names[i])) == 0) {
    calflora = NULL
  } else {
    calflora <- read_csv(paste0(path_calflora, names[i], "_calflora_lowFilter.csv")) %>% 
      dplyr::select(c(ID, Latitude, Longitude, Date)) %>% 
      rename(id = ID,
             lat = Latitude,
             lon = Longitude,
             date = Date) %>% 
      mutate(source = "calflora")
  }

  ## VegBank ------------------
  if (length(list.files(path_vegbank, pattern = names[i])) == 0) {
    vegbank = NULL
  } else {
    vegbank <- read_csv(paste0(path_vegbank, names[i], "_vegbank.csv")) %>% 
      dplyr::select(c(observation_id, latitude, longitude, date)) %>% 
      rename(id = observation_id, 
             lat = latitude,
             lon = longitude) %>% 
      mutate(source = "vegbank") %>% 
      ## check for incorred coord entries
      filter(lon < 0,
             lat > 0)
  }
           

  ## Merge and thin -----------
  combo <- rbind(gbif, calflora, vegbank) %>% 
    mutate(year = lubridate::year(date),
           month = lubridate::month(date),
           .before = source)
  comboThin <- elimCellDuplicates(combo, rast, longLat = c("lon", "lat"))
  
  ## Export
  write_csv(comboThin, paste0(here("data/occ/combined_spp_occ//"), 
                              names[i],
                              "_lowFilter.csv"))
} ## END LOOP

```

#### TESTING: trends in occ data
seasonal trends
```{r}
occ <- read_csv(here("data/occ/combined_spp_occ/a_menziesii_lowFilter.csv"))

## using `tsibble` pkg
library(tsibble)
library(feasts)

## Group by mo/yr
occ_mo_yr <- occ %>% 
  ##also tsibble::yearweek fxn for mosquitoes
  mutate(date = tsibble::yearmonth(date)) %>% 
  group_by(date) %>% 
  summarize(n = n()) %>% 
  as_tsibble(key = NULL, index = date) %>% 
  ## need to explicitly fill in NAs
  ## to run `feast` fxns
  tsibble::fill_gaps()   %>% 
  replace_na(., list(n=0))

## Checking seasonal variation
occ_mo_yr %>% 
  feasts::gg_season(y=n) +
  scale_color_viridis_c()+
  theme_minimal() +
  labs(x="Month",
       y="Occurrences (n)",
       title = "L. pentachaeta")
  ## Also confirms more obs in spring
  # occ_mo_yr %>% 
  #   feasts::gg_subseries(n)+
  #   theme_minimal()

dcmp <- occ_mo_yr %>% 
  model(STL(n ~ season()))
components(dcmp) %>% 
  autoplot()+
  theme_minimal()

```
Annual/monthly trends
```{r}
occ <- read_csv(here("data/occ/combined_spp_occ/a_menziesii_lowFilter.csv"))

occ_yr <- occ %>% 
  ## aggregated data by month of yr
  mutate(date = lubridate::floor_date(date, unit="year")) %>%
  group_by(date) %>% 
  summarize(n = n())
occ_mo <- occ %>% 
  ## aggregated data by month of yr
  mutate(date = lubridate::floor_date(date, unit="months")) %>%
  group_by(date) %>% 
  summarize(n = n())

ggplot() +
  geom_point(data=occ_yr, aes(x=date, y=n)) +
  geom_line(data=occ_yr, aes(x=date, y=n))+
  geom_col(data=occ_mo, aes(x=date, y=n), color = "blue") +
  geom_vline(xintercept = as.numeric(as.Date("2022-10-01")),
                linetype=2, colour="red")+
  # geom_line(data=occ_mo, aes(x=date, y=n), color = "blue")+
  # geom_line(data=occ_yr_mo, aes(x=date, y=n),
  #           color = "blue") +
   # geom_line(test)+
  # scale_x_date(date_breaks = "2 years",
  #              date_labels = "%Y")+
  theme_minimal()+
  labs(title = "A. menziesii")
```



# Background points

Random background occurrence points will be generated using the `dismo` package and exported as a CSV file. Spatially, background points are generated within a 5km range of observed occurrences. Temporally, the relative number of background points per water year matches that of observations. A minimum number of 10,000 points are generated for each species; the exact number slightly varies to accommodate temporal distribution. 

```{r}
names <- c(
  "l_pentachaeta",
  "p_ciliata",
  "a_menziesii")

## Read in fxn
source(here("R/generate_backOcc.R"))
## Fxn parameters
raster = rast(here('data/bcmv8/2000_2022/aet2020dec.tif'))
buffer = 5000

## Generate backOccs for each spp in list
purrr::map(.x=names, function(names) {
  ## read in spp occurrence points
  sppOcc = read_csv(paste0(here("data/occ/combined_spp_occ//"), 
                           names, "_lowFilter.csv"))
  print(paste0("Working on ", names))
  ## Generate pts
  backOcc_pts <- backOcc(sppOcc, raster=raster, buffer)
  ### export
  write_csv(backOcc_pts, paste0(here("data/background/back_"), 
                                names, "_lowfilter_5km.csv"))
})

```



### Omit development and farmland
Test for generating background points omitting development/farm land-use.
A little tricky because land use changes through the years, and background points are assigned years/months at random.
To account for this, we'll use a loop that generates points for one layer (with development as NA) and assign dates within that time span to the points, and save as data frame. This dataframe will then be read in as "presence points" when the next raster is read, to ensure that points aren't generated in the same cells. 
**NOTE** Keeping at 37 per mo/yr for direct comparison, but in future change this to different # that makes match easier 
#### NLCD
```{r}
## List NLCD rasters
rasts <- grep(list.files(here("data/nlcd/rasters"), full.names=TRUE), 
              pattern = ".tif.", invert = TRUE, value = TRUE)
rast_list <- map(rasts, rast)
## Years for looping
yrs <- grep(list.files(here("data/nlcd/rasters"), full.names=FALSE), 
              pattern = ".tif.", invert = TRUE, value = TRUE)
rast_yrs <- ((as.numeric(regmatches(yrs, regexpr("[0-9].*[0-9]", yrs)))) - 1) %>% 
  append(2022)

## Reference raster for res and CA shape
aet_r = rast(here("data/bcmv8/2000_2022/aet2020dec.tif")) %>% 
  project(y=crs(rast_list[[1]]))

## Reclassify so heavy development value 0, all else 1
rcl_m <- matrix(c(0, 23, 1,
                  24, 24, 0, 
                  25, 95, 1), ncol = 3, byrow=TRUE)

## Map reclass/mask fxn across raster list
rast_list_rcl <- map(rast_list, function(x){
  r <- classify(x, rcl_m, right=NA)
  ## Change res from 30m to 270m
  r_agg <- terra::aggregate(r, fact=9, fun="modal")
  ## Resample to mask
  r_resamp <- r_agg %>% 
    resample(., aet_r, method = "near") %>% 
    crop(., aet_r, mask=TRUE)
})



back_noDev <- function(sppOcc) {
  ## Vectorize sppOcc, find convex hull of pts, 
  ## then add buffer
  sppZone <- convHull(vect(sppOcc, 
                          geom = c("lon", "lat"),
                          crs = "WGS84")) %>% 
    buffer(., width = 5000)
  ## Start df for loop ()
  backSamp <- data.frame("x" = NA, "y" = NA, "month"=NA, "year"=NA)
  
  ## Loop through making background points
  for (i in 1:length(rast_list_rcl)) {
    ## Read in raster by year
    rast <- rast_list_rcl[[i]] %>% 
      project(y=crs(sppZone), method = "near") %>% 
      crop(y=sppZone, mask = TRUE) %>% 
      ## Turn 0 to NA
      classify(x=., cbind(0, NA))
    r <- raster(rast)
    
    ## Need slightly different rules for first iteration
    ## First NLCD year is 2001, but we're making points back to 2000,
    ## So need to "add a year" of data 
    if (i == 1) {
      backOcc <- randomPoints(mask = r, 
                            n = (((rast_yrs[i+1] - rast_yrs[i])+1)*444),
                            p = backSamp,
                            excludep = TRUE,
                            prob = FALSE)
      backOcc <- as.data.frame(backOcc)
    
      dates <- data.frame(month = rep(1:12, each = 37),
                          year = rep(2000:rast_yrs[i+1], each = 444))
      dates <- rbind(tail(dates, 111), head(dates, -111))
      dates[1:111, 2] = (dates[112,2] - 1)
    } else {
      backOcc <- randomPoints(mask = r, 
                            n = ((rast_yrs[i+1] - rast_yrs[i])*444),
                            p = backSamp,
                            excludep = TRUE,
                            prob = FALSE)
      backOcc <- as.data.frame(backOcc)
      dates <- data.frame(month = rep(1:12, each = 37),
                          year = rep((rast_yrs[i]+1):rast_yrs[i+1], each = 444))
      dates <- rbind(tail(dates, 111), head(dates, -111))
      dates[1:111, 2] = (dates[112,2] - 1)
    }
    
    back_dates <- cbind(backOcc, dates)
    backSamp <- rbind(backSamp, back_dates)
    
  }##END loop
  ## Remove placeholder "NA" row
  backSamp <- backSamp[-1,]
}##END fxn
  
sppOcc <- read_csv(here("data/occ/combined_spp_occ/a_menziesii_lowFilter.csv"))
backSamp_noDev <- back_noDev(sppOcc)

### export
write_csv(backSamp_noDev,
          here('data/background/back_a_menziesii_lowfilter_noDev_5km.csv'))
```



#### FMMP
```{r}
## List FMMP vectors
vects <- list.files(here("data/fmmp/prime_farmland/"), 
                    pattern = ".shp",
                    full.names=TRUE)
vect_list <- map(vects, function(x) {
  v <- vect(x) %>% 
    project(y="NAD83")
})
## Years for looping
yrs <- seq(2000, 2020, by=2) %>% 
  append(2023)

back_noFarm <- function(sppOcc) {
  ## Vectorize sppOcc, find convex hull of pts, 
  ## then add buffer
  sppZone <- convHull(vect(sppOcc, 
                          geom = c("lon", "lat"),
                          crs = "WGS84")) %>% 
    buffer(., width = 5000)
  ## Start df for loop ()
  backSamp <- data.frame("x" = NA, "y" = NA, "month"=NA, "year"=NA)
  
  ## Loop through making background points
  for (i in 1:length(vect_list)) {
    ## Read in reference raster
    ## and mask by year
    rast <- rast(here('data/bcmv8/2000_2022/aet2020dec.tif')) %>% 
      ## Remove prime farmland
      project(y=crs(vect_list[[i]])) %>% 
      mask(mask=vect_list[[i]], inverse=TRUE, updatevalue=NA) %>%
      ## Keep only area w/in spp zone
      project(y=crs(sppZone)) %>% 
      crop(y=sppZone, mask = TRUE)
    
    r <- raster(rast)

    backOcc <- randomPoints(mask = r, 
                            n = ((yrs[i+1] - yrs[i])*444),
                            p = backSamp,
                            excludep = TRUE,
                            prob = FALSE)
    backOcc <- as.data.frame(backOcc)
    dates <- data.frame(month = rep(1:12, each = 37),
                        year = rep(yrs[i]:(yrs[i+1]-1), each = 444))
    dates <- rbind(tail(dates, 111), head(dates, -111))
    dates[1:111, 2] = (dates[112,2] - 1)
    
    
    back_dates <- cbind(backOcc, dates)
    backSamp <- rbind(backSamp, back_dates)
    
  }##END loop
  ## Remove placeholder "NA" row
  backSamp <- backSamp[-1,]
}##END fxn


sppOcc <- read_csv(here("data/occ/combined_spp_occ/a_menziesii_lowFilter.csv"))
backSamp_noFarm <- back_noFarm(sppOcc)

### export
write_csv(backSamp_noFarm,
          here('data/background/back_a_menziesii_lowfilter_noFarm_5km.csv'))


sppOcc <- read_csv(here("data/occ/combined_spp_occ/l_pentachaeta_lowFilter.csv"))
backSamp_noFarm <- back_noFarm(sppOcc)

### export
write_csv(backSamp_noFarm,
          here('data/background/back_l_pentachaeta_lowfilter_noFarm_5km.csv'))


sppOcc <- read_csv(here("data/occ/combined_spp_occ/p_ciliata_lowFilter.csv"))
backSamp_noFarm <- back_noFarm(sppOcc)

### export
write_csv(backSamp_noFarm,
          here('data/background/back_p_ciliata_lowfilter_noFarm_5km.csv'))

```

