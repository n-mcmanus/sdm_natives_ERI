---
title: "Species Distribution Model for Kern Natives"
author: "Nick McManus"
date: "2023-08-02"
output: html_document
---

```{r setup, include=FALSE, message = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
library(tidyverse)    ## always
library(here)         ## reading/writing data
library(purrr)        ## iterate fxns
library(sf)           ## vector objects
library(terra)        ## Better/faster GIS
library(raster)       ## GIS format required by Dismo
library(dismo)        ## Maxent pkg
library(rJava)        ## Needed for dismo
library(lubridate)    ## Dates and progress bar
library(corrplot)     ## Correlation matrix
```


This script reads in the prepared species occurrence records and background points (produced in `spp_occ_background.Rmd`) to evaluate and run species distribution models. These models are made with Maxent in the `dismo` package.



# Correlation
Assessing the correlation between environmental variables for SDM. Additional derived variables, such as mean temp and difference of temp, are generated. Then a Pearson correlation matrix is produced; based on the values, certain variables may be removed from the final SWD file.

*NOTE:* UPDATE/CLEAN code chunk. Been testing out different variables (like soil taxonomy) as they get added to analysis.
```{r}
backgrd <- read_csv(here('data/swd/a_menziesii/backExtract_a_menziesii_soil200cm_drain_notaxon_lowFilter.csv')) %>% 
  mutate(tmean = (tmx+tmn)/2,
         tdiff = tmx-tmn) %>% 
    dplyr::select(aet:tdiff) 
  # dplyr::select(!c(cwd, pet, tmn, tmn, tmean, ppt_winter_mean)) %>% 

cor <- cor(backgrd, method = "pearson", use = "complete.obs")
corrplot(cor, method = 'number', type = 'upper')

```


Quick test code for PCA
```{r}
back<- read_csv(here("data/swd/a_polycarpa/backExtract_a_polycarpa_200cm_lowFilter.csv"))
apoly <- read_csv(here("data/swd/a_polycarpa/a_polycarpa_200cm_lowFilter.csv"))

back_pca <- back %>% 
  dplyr::select(where(is.numeric)) %>%
  dplyr::select(!c(x:year)) %>% 
  drop_na() %>% 
  # scale() %>%
  prcomp(scale.=TRUE)

apoly_pca <- apoly %>% 
  dplyr::select(where(is.numeric)) %>% 
  dplyr::select(!c(lat:month)) %>% 
  drop_na() %>% 
  prcomp(scale.=TRUE)

back_pca$rotation
apoly_pca$rotation

library(ggfortify)

autoplot(back_pca, 
         loadings = TRUE, loadings.label = TRUE,
         loadings.colour = "black", loadings.label.color = "darkblue",
           loadings.label.size = 4, loadings.label.background = TRUE,
         loadings.label.vjust = -0.5,
         ) +
  theme_minimal()


both <- read_csv(here("data/swd/a_polycarpa/swd_a_polycarpa_200cm_lowFilter.csv")) %>% 
  mutate(presence = factor(presence, levels = c('0', '1')))
both_pca <- both %>% 
  dplyr::select(where(is.numeric)) %>% 
  dplyr::select(!c(x:year)) %>% 
  drop_na() %>% 
  prcomp(scale.=TRUE)

autoplot(both_pca, data = both, loadings = TRUE, loadings.label = TRUE, 
         loadings.label.color = "darkblue",
         colour = "presence")+
    scale_color_manual(values = c( 'orange', 'darkgreen')) +
  scale_fill_manual(values = c('orange',  'darkgreen')) +
  theme_minimal()


screeplot(back_pca, type = "barplot")
```




# Generate Maxent Models

Construct model using Samples with Data (SWD) method.


### Input data

Read in species occurrence and background data, then wrangle to put in proper SWD format. Remove variables (due to high correlation or over-fitting) in this step.
```{r}
names <- c(
  "a_polycarpa",
  "p_arborea",
  "c_pungens",
  "l_pentachaeta",
  "p_ciliata",
  "a_menziesii",
  "c_lasiophyllus"
)

for (i in 1:length(names)){
  ## Occurrence data -----------------------------------------------
  swdOcc <- read_csv(paste0(here('data/swd//'), names[i], 
                            '/occExtract_', names[i],
                            '_soil200cm_drain_lowFilter.csv')) %>% 
  ## Add tmean, tdiff, and presence values
  mutate(tdiff = round(tmx-tmn, 2),
         presence = 1) %>% 
    ## remove select variables
    dplyr::select(!c(id, source, tmn, pet, ppt_winter_mean, date,
                     ## TEST: include cwd and monthly ppt
                     # cwd,ppt
                     # taxon
                     )) %>% 
    ## match background var names
    rename("x" = "lon",
           "y" = "lat") 
  
  ## rearrange x and y to match background df
  swdOcc <- swdOcc[, c(2,1, 4, 3, 5:ncol(swdOcc))]

  
  ## Background Data -------------------------------------------------
  swdBack <- read_csv(paste0(here("data/swd//"), names[i], 
                             "/backExtract_", names[i],
                             "_soil200cm_drain_notaxon_lowFilter.csv")) %>% 
    mutate(tdiff = round(tmx-tmn, 2),
           presence = 0) %>% 
    dplyr::select(!c(tmn, pet, ppt_winter_mean,
                     ##TEST: keep these vars
                     # cwd, ppt
                     ))


  ## ----------------------------------------------------------------
  ## Bind into one df and
  ## remove any rows in NAs
  swd <- rbind(swdOcc, swdBack)
  swd <- swd[complete.cases(swd),]
  
  write_csv(swd, paste0(here("data/swd//"), names[i], 
                        "/swd_", names[i],
                        "_soil200cm_cwdppt_drain_notaxon_lowFilter.csv"))
}

```
 

### Model fitting
Fitting w/ENMeval
- spatial partitioning methods preferable to random k-fold bc w/large occurrence dataset, it could randomly resut in spatial clustering. Other methods address spatial autocorrelation better (Roberts et al. 2017)
**NOTE:** CLEAN UP THIS SECTION. More definitive fitting code using ENMeval only
```{r}
library(ENMeval)

### occ and background can only be lon/lat
occ <- swdOcc %>% 
  dplyr::select(x, y)

bg <- swdBack %>% 
  dplyr::select(x,y)

block <- get.block(occ, bg, orientation = "lat_lon")
## check for even number in each group
# table(block$occs.grp)
# 1   2   3   4 
# 153 153 153 152 

# Evaluating --------------------------------------
occs.z <- swdOcc %>% 
  dplyr::select(!c(month, year, presence))%>%
  mutate(order = as.factor(order),
         series = as.factor(series)) %>% 
  mutate(order = unclass(order),
         series = unclass(series)) %>% 
  mutate(order = as.factor(order),
         series = as.factor(series))
bg.z <- swdBack %>% 
  dplyr::select(!c(month, year, presence))%>%
  mutate(order = as.factor(order),
         series = as.factor(series)) %>% 
  mutate(order = unclass(order),
         series = unclass(series)) %>% 
  mutate(order = as.factor(order),
         series = as.factor(series))

e.swd <- ENMevaluate(occs.z, bg=bg.z, algorith = "maxnet",
                     tune.args = list(fc = c("L", "LQ","LQH"),
                                      rm = seq(0.5,2, by=0.5)), 
                     partitions = "randomkfold")

e.swd
eval.tune.settings(e.swd)
eval.results(e.swd)
eval.results.partitions(e.swd)
evalplot.stats(e=e.swd, stats = c("or.mtp", "auc.val"), 
               color = "fc", x.var = "rm", error.bars = FALSE)
```


Fitting w/dismo??
```{r}
## Select env predictors for model (presence + background)
swd <- read_csv(here('data/swd/a_menziesii/270soil/swd_a_menziesii_270soil_notaxon_200cm_lowFilter.csv'))

## Select env predictors for model (presence + background)
x <- swd %>% 
  dplyr::select(aet:tdiff) 
## Testing for soil taxonomy
## Dismo says must be factors, but also numbers?
## Factor them, then turn into numbers, then factor again
x.soil <- x %>%
  mutate(order = as.factor(order),
         series = as.factor(series)) %>% 
  mutate(order = unclass(order),
         series = unclass(series)) %>% 
  mutate(order = as.factor(order),
         series = as.factor(series))

## Specify occurrence data
p <- swd %>% 
  dplyr::select(presence)

## Arguments/options to pass to Maxent()
args <- c('jackknife=TRUE', 
          'autofeature=TRUE', 
          'responsecurves=TRUE', 
          'linear=TRUE',
          'quadratic=TRUE',
          'threshold=FALSE',
          'hinge=FALSE',
          # 'maximumiterations=100000',
          'randomtestpoints=25')
          # 'replicates=5', 'replicatetype=crossvalidate')

## Path to save results
path <- here('data/maxent_outputs/a_menziesii/270soil/notaxon/fitting/')



## Run test model
testModel <- maxent(x, p, path=path, args=args, removeDuplicates = TRUE)
```


### Final model

```{r}
for (i in 1:length(names)) {
    ## Read in all points
  swd <- read_csv(paste0(here("data/swd//"), names[i], 
                        "/swd_", names[i], "_soil200cm_cwdppt_drain_notaxon_lowFilter.csv"))
  
  ## Select env predictors for model (presence + background)
  x <- swd %>% 
    dplyr::select(aet:tdiff) %>% 
    # mutate(taxon = as.factor(taxon)) %>%
    mutate(drainage = as.factor(drainage))
    # dplyr::select(!c(ppt, tdiff))
  
  ## Specify occurrence data
  p <- swd %>% 
    dplyr::select(presence)
  
  ## Set Arguments/Options to Pass to Maxent
  args <- c('jackknife=TRUE', 
            'autofeature=TRUE', 
            'responsecurves=TRUE', 
            'linear=TRUE',
            'quadratic=TRUE',
            'product=TRUE',
            'threshold=FALSE',
            'hinge=FALSE', 
            'maximumiterations=100000', 
            'writeplotdata=TRUE')
  
  ## Path to save results
  path <- paste0(here('data/maxent_outputs//'),
                      names[i], '/lowFilter/model/cwd_ppt/notaxon/drain/')
  
  #Final Model Creation
  model <- maxent(x, p, path=path, args=args)

  save(model, file = paste0(path, "/", names[i], "_sdm.rData"))
}

```



# Predictions

Now, we want to project the Maxent model predictions for each month to determine how suitability changes during the year. 

### Run by month:

Testing out prediction maps using only one year of monthly env data. 
NOTE; testing out how to make this fxn work with user defined name/amount of variables w/o having to manually change the function... will think more on later.
```{r}
names <- c(
  # "a_polycarpa",
  # "p_arborea",
  "c_pungens",
  "l_pentachaeta",
  "p_ciliata",
  "a_menziesii",
  "c_lasiophyllus"
)

## Read in fxn
source(here('R/pred_month.R'))

## Loop fxn for all spp
for (i in 1:length(names)) {
  ## Read in Maxent model
  print(paste0("Working on ", names[i]))
  load(paste0(here("data/maxent_outputs//"), names[1],
              ##CHANGE next time
              "/lowFilter/model/cwd_ppt/notaxon/drain/",
              names[1], "_sdm.rData"))
  ## Run fxn
  ## CHANGE "testFinal" ON NEXT RUN
  pred_month(model = model,
             bcmPath = here("data/bcmv8/monthly_avgs//"),
             soilPath = here("data/natsgo/rasters//"),
             pathOut = paste0(here("data/maxent_outputs//"),
                              names[1], 
                              "/lowFilter/monthly_rasters/cwd_ppt/drain//")
             )
}

```



























